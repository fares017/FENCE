# Reproduction of the Malicious Network Traffic Classification of FENCE paper

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)


This project is a reproduction of the paper Feasible Evasion Attacks on Neural Networks in Constrained Environments, precisely the experiment Malicious Network Traffic Classification.

## Table of Contents

- [Attack](#installation)
- [Botnet detector using machine learning](#usage)


## Attack folder
The attack folder, contains python files that you can use to attack the a pretrained model using the FENCE framework.
To run the attack against pretrained model using FENCE, you need to run the file located at: attack.ipynb.
The file Evalution of Adeversarial training.ipynb contains the code, in order to evaluate the model trained with adversarial training.

To run the attack against a pretrained model using FENCE, run the file located at: attack/attack.ipynb
# Example installation commands
npm install
npm start
