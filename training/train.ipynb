{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "756d4bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "#os.environ['PYTHONHASHSEED']=str(2)\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import random as rn\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from datagen import generate_adversarial_batch_pgd, generate_adversarial_batch_fence\n",
    "from helpers import create_DNN, save_metrics, save_adv_candidates, read_min_max\n",
    "from helpers import get_train_data, get_model_data, get_processing_data\n",
    "#rn.seed(2)\n",
    "#tf.random.set_seed(2)\n",
    "#np.random.seed(2)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13d39dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, method='clean', callback=None, distance=16,  save_data=True):\n",
    "\n",
    "    x_train, y_train, x_test, y_test = get_train_data(config)\n",
    "    LAYERS, INPUT_DIM, LR = get_model_data(config)\n",
    "    scaler, min_features, max_features = get_processing_data(config)\n",
    "    iterations = config[\"iterations\"]\n",
    "    epochs = config[\"epochs\"]\n",
    "    epochs = 1\n",
    "    ##Only for FENCE attack\n",
    "    intermediate_model_path = config[\"intermediate_model_path\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for lrate in LR:\n",
    "        nn =  create_DNN(units = LAYERS, input_dim_param = INPUT_DIM, lr_param = lrate)\n",
    "\n",
    "        if method == \"clean\":\n",
    "            history_obj = nn.fit(x_train, y_train, verbose=1, epochs=epochs, batch_size=64,  shuffle=True)\n",
    "\n",
    "        if method == \"fence\":\n",
    "            dataGen = generate_adversarial_batch_fence(nn, 64, x_train, y_train, distance, iterations, scaler, min_features, max_features, intermediate_model_path)\n",
    "            history_obj = nn.fit(dataGen, steps_per_epoch=len(x_train) // 64, verbose = 1, epochs = epochs, callbacks=callback,)\n",
    "\n",
    "        if save_data==True:\n",
    "            ## model\n",
    "            model_path = config[\"path_to_save\"] + f\"/{attack}_model_new17.h5\"\n",
    "            nn.save(model_path)\n",
    "\n",
    "            ## history\n",
    "            history_path = config[\"path_to_save\"] + f\"/{attack}_model_history_new17.npy\"\n",
    "            with open(history_path , 'wb') as f:\n",
    "                pickle.dump(history_obj.history, f) \n",
    "\n",
    "            probas = np.squeeze(nn.predict(x_test))\n",
    "            predictions = np.squeeze((probas>= 0.5).astype(int))\n",
    "            ## metrics\n",
    "            metrics_path = config[\"path_to_save\"] + f\"/{attack}_model_metrics_new17.pickle\"\n",
    "            save_metrics(y_test, predictions, metrics_path)\n",
    "\n",
    "            ## adversarial candidates\n",
    "            adv_candidates_path = config[\"path_to_save\"] + \"initial_states_new17.npy\"\n",
    "            save_adv_candidates(x_test, y_test, predictions, adv_candidates_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b7f9db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_save_epochs(config, attack):\n",
    "    file = open(config_file)\n",
    "    config = json.load(file)\n",
    "    distances = config[\"distances\"]\n",
    "    print(distances)\n",
    "    for i, dis in enumerate(distances):\n",
    "        checkpoint_path =  config[\"path_to_save\"] + f\"/distance_{distances[i]}\"\n",
    "        checkpoint_path = checkpoint_path + \"/model-{epoch:04d}.h5\"\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_freq=\"epoch\", save_weights_only=False,  save_best_only=False, verbose=1)\n",
    "        train(config, method=attack,  callback=cp_callback, distance=int(dis), save_data=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7671596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12']\n",
      "[256, 128, 64]\n",
      "2235/2235 [==============================] - ETA: 0s - loss: 0.0191 \n",
      "Epoch 1: saving model to ../out/neris/clean_10epochs/distance_12\\model-0001.h5\n",
      "2235/2235 [==============================] - 39246s 18s/step - loss: 0.0191\n",
      "1722/1722 [==============================] - 3s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    config_file = \"config/neris.json\" \n",
    "    attack = \"fence\" \n",
    "\n",
    "    train_save_epochs(config_file, attack)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab89e908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2166d791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FP_env",
   "language": "python",
   "name": "fp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
